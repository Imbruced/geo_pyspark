{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import StorageLevel\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import LongType\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from geo_pyspark.register import GeoSparkRegistrator\n",
    "from geo_pyspark.register import upload_jars\n",
    "from geo_pyspark.core.SpatialRDD import SpatialRDD\n",
    "from geo_pyspark.core.SpatialRDD import PointRDD\n",
    "from geo_pyspark.core.SpatialRDD import PolygonRDD\n",
    "from geo_pyspark.core.SpatialRDD import LineStringRDD\n",
    "from geo_pyspark.core.enums import FileDataSplitter\n",
    "from geo_pyspark.utils.adapter import Adapter\n",
    "from geo_pyspark.core.spatialOperator import KNNQuery\n",
    "from geo_pyspark.core.spatialOperator import JoinQuery\n",
    "from geo_pyspark.core.spatialOperator import RangeQuery\n",
    "from geo_pyspark.core.formatMapper.shapefileParser import ShapefileReader\n",
    "from geo_pyspark.core.formatMapper import WkbReader\n",
    "from geo_pyspark.core.formatMapper import WktReader\n",
    "from geo_pyspark.core.formatMapper import GeoJsonReader\n",
    "from geo_pyspark.sql.types import GeometryType\n",
    "from geo_pyspark.core.enums import GridType\n",
    "from geo_pyspark.core.SpatialRDD import RectangleRDD\n",
    "from geo_pyspark.core.enums import IndexType\n",
    "from geo_pyspark.core.geom.envelope import Envelope\n",
    "from geo_pyspark.utils import GeoSparkKryoRegistrator, KryoSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This step is optional, if you have jar files already copied to $SPARK_HOME/jars,\n",
    "# there is no need to use that function\n",
    "upload_jars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "    builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    appName(\"GeoPySparkCoreExample\").\\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName).\\\n",
    "    config(\"spark.kryo.registrator\", GeoSparkKryoRegistrator.getName) .\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register function is essential for GeoSpark Core and GeoSparkSQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeoSparkRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SpatialRDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading to PointRDD from CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want load the CSV file into GeoSpark PointRDD\n",
    "```\n",
    "testattribute0,-88.331492,32.324142,testattribute1,testattribute2\n",
    "testattribute0,-88.175933,32.360763,testattribute1,testattribute2\n",
    "testattribute0,-88.388954,32.357073,testattribute1,testattribute2\n",
    "testattribute0,-88.221102,32.35078,testattribute1,testattribute2\n",
    "testattribute0,-88.323995,32.950671,testattribute1,testattribute2\n",
    "testattribute0,-88.231077,32.700812,testattribute1,testattribute2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_rdd = PointRDD(sc, \"data/arealm-small.csv\", 1, FileDataSplitter.CSV, True, 10, StorageLevel.MEMORY_ONLY, \"epsg:4326\", \"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting approximate total count\n",
    "point_rdd.approximateTotalCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-176.64696132 26.718666680000002 95.20719264000002 48.162659640000015\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,101.59999300000001)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"1.9041438528000003\" opacity=\"0.6\" d=\"M -173.120769,30.244859 L -173.120769,71.355134 L -84.965961,71.355134 L -84.965961,30.244859 L -173.120769,30.244859 z\" /></g></svg>"
      ],
      "text/plain": [
       "<geo_pyspark.core.geom.envelope.Envelope at 0x7f2f66489650>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting boundary for PointRDD or any other SpatialRDD, it returns Enelope object which inherits from\n",
    "# shapely.geometry.Polygon\n",
    "point_rdd.boundary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To run analyze please use function analyze\n",
    "point_rdd.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-176.64696132 26.718666680000002 95.20719264000002 48.162659640000015\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,101.59999300000001)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"1.9041438528000003\" opacity=\"0.6\" d=\"M -173.120769,30.244859 L -173.120769,71.355134 L -84.965961,71.355134 L -84.965961,30.244859 L -173.120769,30.244859 z\" /></g></svg>"
      ],
      "text/plain": [
       "<geo_pyspark.core.geom.envelope.Envelope at 0x7f2f65f4a610>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding boundary envelope for PointRDD or any other SpatialRDD, it returns Enelope object which inherits from\n",
    "# shapely.geometry.Polygon\n",
    "point_rdd.boundaryEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2996"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate number of records without duplicates\n",
    "point_rdd.countWithoutDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting filed names for PointRDD or other SpatialRDD, it return list with field names\n",
    "point_rdd.fieldNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsg:4326'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geting source epsg code\n",
    "point_rdd.getSourceEpsgCode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'epsg:4326'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Geting target epsg code\n",
    "point_rdd.getTargetEpsgCode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spatial partitioning data\n",
    "point_rdd.spatialPartitioning(GridType.EQUALGRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<geo_pyspark.core.geom.envelope.Envelope at 0x7f2f662fde90>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f662b6d10>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f662b6590>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f662b68d0>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f65f5f2d0>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f65f5ff50>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f65f5f990>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f6608a9d0>,\n",
       " <geo_pyspark.core.geom.envelope.Envelope at 0x7f2f6608ae50>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get PointRDD or other SpatialRDD, it returns list of Envelopes \n",
    "point_rdd.grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spatial partitioning data\n",
    "point_rdd.spatialPartitioning(GridType.VORONOI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on RawSpatialRDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rawSpatialRDD method returns RDD which consists of GeoData objects which has 2 attributes\n",
    "<li> geom: shapely.geometry.BaseGeometry </li>\n",
    "<li> userData: str </li>\n",
    "\n",
    "You can use any operations on those objects and spread across machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Geometry: Point userData: testattribute0\ttestattribute1\ttestattribute2]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take firs element\n",
    "point_rdd.rawSpatialRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Geometry: Point userData: testattribute0\ttestattribute1\ttestattribute2,\n",
       " Geometry: Point userData: testattribute0\ttestattribute1\ttestattribute2,\n",
       " Geometry: Point userData: testattribute0\ttestattribute1\ttestattribute2,\n",
       " Geometry: Point userData: testattribute0\ttestattribute1\ttestattribute2,\n",
       " Geometry: Point userData: testattribute0\ttestattribute1\ttestattribute2]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect to Python list\n",
    "point_rdd.rawSpatialRDD.collect()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111.08786851399313,\n",
       " 110.92828303170774,\n",
       " 111.1385974283527,\n",
       " 110.97450594034112,\n",
       " 110.97122518072091]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply map functions, for example distance to Point(52 21)\n",
    "point_rdd.rawSpatialRDD.map(lambda x: x.geom.distance(Point(21, 52))).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming to GeoPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaded data can be transfomred to GeoPandas DataFrame few ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_rdd_to_geo = point_rdd.rawSpatialRDD.map(lambda x: [x.geom, *x.getUserData().split(\"\\t\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_gdf = gpd.GeoDataFrame(\n",
    "    point_rdd_to_geo.collect(), columns=[\"geom\", \"attr1\", \"attr2\", \"attr3\"], geometry=\"geom\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geom</th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-88.33149 32.32414)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (-88.17593 32.36076)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (-88.38895 32.35707)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (-88.22110 32.35078)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (-88.32399 32.95067)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         geom           attr1           attr2           attr3\n",
       "0  POINT (-88.33149 32.32414)  testattribute0  testattribute1  testattribute2\n",
       "1  POINT (-88.17593 32.36076)  testattribute0  testattribute1  testattribute2\n",
       "2  POINT (-88.38895 32.35707)  testattribute0  testattribute1  testattribute2\n",
       "3  POINT (-88.22110 32.35078)  testattribute0  testattribute1  testattribute2\n",
       "4  POINT (-88.32399 32.95067)  testattribute0  testattribute1  testattribute2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_gdf[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_df = Adapter.\\\n",
    "    toDf(point_rdd, [\"attr1\", \"attr2\", \"attr3\"], spark).\\\n",
    "    createOrReplaceTempView(\"spatial_df\")\n",
    "\n",
    "spatial_gdf = spark.sql(\"Select attr1, attr2, attr3, st_GeomFromWKT(geometry) as geom from spatial_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+----------------------------+\n",
      "|attr1         |attr2         |attr3         |geom                        |\n",
      "+--------------+--------------+--------------+----------------------------+\n",
      "|testattribute0|testattribute1|testattribute2|POINT (-88.331492 32.324142)|\n",
      "|testattribute0|testattribute1|testattribute2|POINT (-88.175933 32.360763)|\n",
      "|testattribute0|testattribute1|testattribute2|POINT (-88.388954 32.357073)|\n",
      "|testattribute0|testattribute1|testattribute2|POINT (-88.221102 32.35078) |\n",
      "|testattribute0|testattribute1|testattribute2|POINT (-88.323995 32.950671)|\n",
      "+--------------+--------------+--------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spatial_gdf.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "      <td>POINT (-88.33149 32.32414)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "      <td>POINT (-88.17593 32.36076)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "      <td>POINT (-88.38895 32.35707)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "      <td>POINT (-88.22110 32.35078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "      <td>POINT (-88.32399 32.95067)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            attr1           attr2           attr3                        geom\n",
       "0  testattribute0  testattribute1  testattribute2  POINT (-88.33149 32.32414)\n",
       "1  testattribute0  testattribute1  testattribute2  POINT (-88.17593 32.36076)\n",
       "2  testattribute0  testattribute1  testattribute2  POINT (-88.38895 32.35707)\n",
       "3  testattribute0  testattribute1  testattribute2  POINT (-88.22110 32.35078)\n",
       "4  testattribute0  testattribute1  testattribute2  POINT (-88.32399 32.95067)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.GeoDataFrame(spatial_gdf.toPandas(), geometry=\"geom\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DataFrame creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"geometry\", GeometryType(), False),\n",
    "        StructField(\"attr1\", StringType(), False),\n",
    "        StructField(\"attr2\", StringType(), False),\n",
    "        StructField(\"attr3\", StringType(), False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = spark.createDataFrame(point_rdd_to_geo, schema, verifySchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-88.33149 32.32414)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (-88.17593 32.36076)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (-88.38895 32.35707)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (-88.22110 32.35078)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (-88.32399 32.95067)</td>\n",
       "      <td>testattribute0</td>\n",
       "      <td>testattribute1</td>\n",
       "      <td>testattribute2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     geometry           attr1           attr2           attr3\n",
       "0  POINT (-88.33149 32.32414)  testattribute0  testattribute1  testattribute2\n",
       "1  POINT (-88.17593 32.36076)  testattribute0  testattribute1  testattribute2\n",
       "2  POINT (-88.38895 32.35707)  testattribute0  testattribute1  testattribute2\n",
       "3  POINT (-88.22110 32.35078)  testattribute0  testattribute1  testattribute2\n",
       "4  POINT (-88.32399 32.95067)  testattribute0  testattribute1  testattribute2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.GeoDataFrame(geo_df.toPandas(), geometry=\"geometry\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Typed SpatialRDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently The library supports 5 typed SpatialRDDs:\n",
    "<li> RectangleRDD </li>\n",
    "<li> PointRDD </li>\n",
    "<li> PolygonRDD </li>\n",
    "<li> LineStringRDD </li>\n",
    "<li> CircleRDD </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangle_rdd = RectangleRDD(sc, \"data/zcta510-small.csv\", FileDataSplitter.CSV, True, 11)\n",
    "point_rdd = PointRDD(sc, \"data/arealm-small.csv\", 1, FileDataSplitter.CSV, False, 11)\n",
    "polygon_rdd = PolygonRDD(sc, \"data/primaryroads-polygon.csv\", FileDataSplitter.CSV, True, 11)\n",
    "linestring_rdd = LineStringRDD(sc, \"data/primaryroads-linestring.csv\", FileDataSplitter.CSV, True, StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rectangle_rdd.analyze()\n",
    "point_rdd.analyze()\n",
    "polygon_rdd.analyze()\n",
    "linestring_rdd.analyze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoSpark spatial partitioning method can significantly speed up the join query. Three spatial partitioning methods are available: KDB-Tree, Quad-Tree and R-Tree. Two SpatialRDD must be partitioned by the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_rdd.spatialPartitioning(GridType.KDBTREE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoSpark provides two types of spatial indexes, Quad-Tree and R-Tree. Once you specify an index type, GeoSpark will build a local tree index on each of the SpatialRDD partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_rdd.buildIndex(IndexType.RTREE, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpatialJoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial join is operation which combines data based on spatial relations like:\n",
    "<li> intersects </li>\n",
    "<li> touches </li>\n",
    "<li> within </li>\n",
    "<li> etc </li>\n",
    "\n",
    "To Use Spatial Join in GeoPyspark library please use JoinQuery object, which has implemented below methods:\n",
    "```python\n",
    "SpatialJoinQuery(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
    "\n",
    "DistanceJoinQuery(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
    "\n",
    "spatialJoin(queryWindowRDD: SpatialRDD, objectRDD: SpatialRDD, joinParams: JoinParams) -> RDD\n",
    "\n",
    "DistanceJoinQueryFlat(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
    "\n",
    "SpatialJoinQueryFlat(spatialRDD: SpatialRDD, queryRDD: SpatialRDD, useIndex: bool, considerBoundaryIntersection: bool) -> RDD\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example SpatialJoinQueryFlat PointRDD with RectangleRDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning the data\n",
    "point_rdd.spatialPartitioning(GridType.KDBTREE)\n",
    "rectangle_rdd.spatialPartitioning(point_rdd.getPartitioner())\n",
    "# building an index\n",
    "point_rdd.buildIndex(IndexType.RTREE, True)\n",
    "# Perform Spatial Join Query\n",
    "result = JoinQuery.SpatialJoinQueryFlat(point_rdd, rectangle_rdd, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As result we will get RDD[GeoData, GeoData]\n",
    "It can be used like any other Python RDD. You can use map, take, collect and other functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[103] at map at GeoSerializerData.scala:137"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Geometry: Polygon userData: , Geometry: Point userData: ],\n",
       " [Geometry: Polygon userData: , Geometry: Point userData: ]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Geometry: Polygon userData: , Geometry: Point userData: ],\n",
       " [Geometry: Polygon userData: , Geometry: Point userData: ],\n",
       " [Geometry: Polygon userData: , Geometry: Point userData: ]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.collect()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting distance useing SpatialObjects\n",
    "result.map(lambda x: x[0].geom.distance(x[1].geom)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010747596697999453,\n",
       " 0.010747596697999453,\n",
       " 0.010747596697999453,\n",
       " 0.010747596697999453,\n",
       " 0.026651558685001447]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting area of polygon data\n",
    "result.map(lambda x: x[0].geom.area).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on result you can create DataFrame object, using map function and buld DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"geom_left\", GeometryType(), False),\n",
    "        StructField(\"geom_right\", GeometryType(), False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|           geom_left|          geom_right|\n",
      "+--------------------+--------------------+\n",
      "|POLYGON ((-86.749...|POINT (-86.736302...|\n",
      "|POLYGON ((-86.749...|POINT (-86.735506...|\n",
      "|POLYGON ((-86.749...|POINT (-86.68645 ...|\n",
      "|POLYGON ((-86.749...|POINT (-86.675405...|\n",
      "|POLYGON ((-87.229...|POINT (-87.105455...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set verifySchema to False\n",
    "spatial_join_result = result.map(lambda x: [x[0].geom, x[1].geom])\n",
    "spark.createDataFrame(spatial_join_result, schema, verifySchema=False).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above code produces DataFrame with geometry Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geom_left: geometry (nullable = false)\n",
      " |-- geom_right: geometry (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(spatial_join_result, schema, verifySchema=False).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create DataFrame object from Spatial Pair RDD using Adapter object as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+-----+\n",
      "|              geom_1|attr1|              geom_2|attr2|\n",
      "+--------------------+-----+--------------------+-----+\n",
      "|POLYGON ((-86.749...|     |POINT (-86.736302...|     |\n",
      "|POLYGON ((-86.749...|     |POINT (-86.735506...|     |\n",
      "|POLYGON ((-86.749...|     |POINT (-86.68645 ...|     |\n",
      "|POLYGON ((-86.749...|     |POINT (-86.675405...|     |\n",
      "|POLYGON ((-87.229...|     |POINT (-87.105455...|     |\n",
      "+--------------------+-----+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Adapter.toDf(result, [\"attr1\"], [\"attr2\"], spark).show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also produce DataFrame with geometry DataType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geom_1: geometry (nullable = true)\n",
      " |-- attr1: string (nullable = true)\n",
      " |-- geom_2: geometry (nullable = true)\n",
      " |-- attr2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Adapter.toDf(result, [\"attr1\"], [\"attr2\"], spark).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create RDD which will be of type RDD[GeoData, List[GeoData]]\n",
    "We can for example calculate number of Points within some polygon data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that we can use code specified below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_rdd.spatialPartitioning(GridType.KDBTREE)\n",
    "rectangle_rdd.spatialPartitioning(point_rdd.getPartitioner())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_join_result_non_flat = JoinQuery.SpatialJoinQuery(point_rdd, rectangle_rdd, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of point for each polygon\n",
    "number_of_points = spatial_join_result_non_flat.map(lambda x: [x[0].geom, x[1].__len__()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"geometry\", GeometryType(), False),\n",
    "    StructField(\"number_of_points\", LongType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|            geometry|number_of_points|\n",
      "+--------------------+----------------+\n",
      "|POLYGON ((-86.697...|               1|\n",
      "|POLYGON ((-87.082...|              12|\n",
      "|POLYGON ((-87.105...|              15|\n",
      "|POLYGON ((-86.860...|              12|\n",
      "|POLYGON ((-87.114...|              15|\n",
      "|POLYGON ((-86.749...|               4|\n",
      "|POLYGON ((-86.816...|               6|\n",
      "|POLYGON ((-87.229...|               7|\n",
      "|POLYGON ((-87.285...|              26|\n",
      "|POLYGON ((-87.092...|               5|\n",
      "+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(number_of_points, schema, verifySchema=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial KNNQuery is operation which help us find answer which k number of geometries lays closest to other geometry.\n",
    "\n",
    "For Example:\n",
    "    5 closest Shops to your home. To use Spatial KNNQuery please use object \n",
    "<b> KNNQuery </b> which has one method:\n",
    "```python\n",
    "SpatialKnnQuery(spatialRDD: SpatialRDD, originalQueryPoint: BaseGeometry, k: int,  useIndex: bool)-> List[GeoData]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds 5 closests points from PointRDD to given Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = KNNQuery.SpatialKnnQuery(point_rdd, Point(-84.01, 34.01), 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Geometry: Point userData: ,\n",
       " Geometry: Point userData: ,\n",
       " Geometry: Point userData: ,\n",
       " Geometry: Point userData: ,\n",
       " Geometry: Point userData: ]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Reference geometry you can also use Polygon or LineString object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = Polygon(\n",
    "    [(-84.237756, 33.904859), (-84.237756, 34.090426),\n",
    "     (-83.833011, 34.090426), (-83.833011, 33.904859),\n",
    "     (-84.237756, 33.904859)\n",
    "    ])\n",
    "polygons_nearby = KNNQuery.SpatialKnnQuery(polygon_rdd, polygon, 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Geometry: Polygon userData: ,\n",
       " Geometry: Polygon userData: ,\n",
       " Geometry: Polygon userData: ,\n",
       " Geometry: Polygon userData: ,\n",
       " Geometry: Polygon userData: ]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons_nearby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLYGON ((-84.031975 34.043824, -84.031975 34.131247, -83.959903 34.131247, -83.959903 34.043824, -84.031975 34.043824))'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons_nearby[0].geom.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RangeQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A spatial range query takes as input a range query window and an SpatialRDD and returns all geometries that intersect / are fully covered by the query window. \n",
    "RangeQuery has one method:\n",
    "\n",
    "```python\n",
    "SpatialRangeQuery(self, spatialRDD: SpatialRDD, rangeQueryWindow: BaseGeometry, considerBoundaryIntersection: bool, usingIndex: bool) -> RDD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_envelope = Envelope(-85.01, -60.01, 34.01, 50.01)\n",
    "\n",
    "result_range_query = RangeQuery.SpatialRangeQuery(linestring_rdd, query_envelope, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[185] at map at GeoSerializerData.scala:82"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_range_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Geometry: LineString userData: ,\n",
       " Geometry: LineString userData: ,\n",
       " Geometry: LineString userData: ,\n",
       " Geometry: LineString userData: ,\n",
       " Geometry: LineString userData: ,\n",
       " Geometry: LineString userData: ]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_range_query.take(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"geometry\", GeometryType(), False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            geometry|\n",
      "+--------------------+\n",
      "|LINESTRING (-72.1...|\n",
      "|LINESTRING (-72.4...|\n",
      "|LINESTRING (-72.4...|\n",
      "|LINESTRING (-73.4...|\n",
      "|LINESTRING (-73.6...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(\n",
    "    result_range_query.map(lambda x: [x.geom]),\n",
    "    schema,\n",
    "    verifySchema=False\n",
    ").show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load From other Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoPyspark allows to load the data from other Data formats like:\n",
    "<li> GeoJSON </li>\n",
    "<li> Shapefile </li>\n",
    "<li> WKB </li>\n",
    "<li> WKT </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ShapeFile - load to SpatialRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_rdd = ShapefileReader.readToGeometryRDD(sc, \"data/polygon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<geo_pyspark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f64b15940d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|            geometry|_c1|\n",
      "+--------------------+---+\n",
      "|MULTIPOLYGON (((1...|   |\n",
      "|MULTIPOLYGON (((-...|   |\n",
      "|MULTIPOLYGON (((1...|   |\n",
      "|POLYGON ((118.362...|   |\n",
      "|MULTIPOLYGON (((-...|   |\n",
      "+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Adapter.toDf(shape_rdd, spark).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GeoJSON - load to SpatialRDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{ \"type\": \"Feature\", \"properties\": { \"STATEFP\": \"01\", \"COUNTYFP\": \"077\", \"TRACTCE\": \"011501\", \"BLKGRPCE\": \"5\", \"AFFGEOID\": \"1500000US010770115015\", \"GEOID\": \"010770115015\", \"NAME\": \"5\", \"LSAD\": \"BG\", \"ALAND\": 6844991, \"AWATER\": 32636 }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -87.621765, 34.873444 ], [ -87.617535, 34.873369 ], [ -87.6123, 34.873337 ], [ -87.604049, 34.873303 ], [ -87.604033, 34.872316 ], [ -87.60415, 34.867502 ], [ -87.604218, 34.865687 ], [ -87.604409, 34.858537 ], [ -87.604018, 34.851336 ], [ -87.603716, 34.844829 ], [ -87.603696, 34.844307 ], [ -87.603673, 34.841884 ], [ -87.60372, 34.841003 ], [ -87.603879, 34.838423 ], [ -87.603888, 34.837682 ], [ -87.603889, 34.83763 ], [ -87.613127, 34.833938 ], [ -87.616451, 34.832699 ], [ -87.621041, 34.831431 ], [ -87.621056, 34.831526 ], [ -87.62112, 34.831925 ], [ -87.621603, 34.8352 ], [ -87.62158, 34.836087 ], [ -87.621383, 34.84329 ], [ -87.621359, 34.844438 ], [ -87.62129, 34.846387 ], [ -87.62119, 34.85053 ], [ -87.62144, 34.865379 ], [ -87.621765, 34.873444 ] ] ] } },\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_json_rdd = GeoJsonReader.readToGeometryRDD(sc, \"data/testPolygon.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<geo_pyspark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f64b1744b10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_json_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------+-------+--------+--------------------+------------+----+----+--------+\n",
      "|            geometry|STATEFP|COUNTYFP|TRACTCE|BLKGRPCE|            AFFGEOID|       GEOID|NAME|LSAD|   ALAND|\n",
      "+--------------------+-------+--------+-------+--------+--------------------+------------+----+----+--------+\n",
      "|POLYGON ((-87.621...|     01|     077| 011501|       5|1500000US01077011...|010770115015|   5|  BG| 6844991|\n",
      "|POLYGON ((-85.719...|     01|     045| 021102|       4|1500000US01045021...|010450211024|   4|  BG|11360854|\n",
      "|POLYGON ((-86.000...|     01|     055| 001300|       3|1500000US01055001...|010550013003|   3|  BG| 1378742|\n",
      "|POLYGON ((-86.574...|     01|     089| 001700|       2|1500000US01089001...|010890017002|   2|  BG| 1040641|\n",
      "|POLYGON ((-85.382...|     01|     069| 041400|       1|1500000US01069041...|010690414001|   1|  BG| 8243574|\n",
      "+--------------------+-------+--------+-------+--------+--------------------+------------+----+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Adapter.toDf(geo_json_rdd, spark).drop(\"AWATER\").show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WKT - loading to SpatialRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkt_rdd = WktReader.readToGeometryRDD(sc, \"data/county_small.tsv\", 0, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<geo_pyspark.core.SpatialRDD.spatial_rdd.SpatialRDD at 0x7f64b1400710>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkt_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geometry: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Adapter.toDf(wkt_rdd, spark).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+--------+-----+---------+----------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+\n",
      "|            geometry|_c1|_c2|     _c3|  _c4|      _c5|             _c6|_c7|_c8|  _c9|_c10| _c11|_c12|_c13|      _c14|    _c15|       _c16|        _c17|\n",
      "+--------------------+---+---+--------+-----+---------+----------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+\n",
      "|POLYGON ((-97.019...| 31|039|00835841|31039|   Cuming|   Cuming County| 06| H1|G4020|    |     |    |   A|1477895811|10447360|+41.9158651|-096.7885168|\n",
      "|POLYGON ((-123.43...| 53|069|01513275|53069|Wahkiakum|Wahkiakum County| 06| H1|G4020|    |     |    |   A| 682138871|61658258|+46.2946377|-123.4244583|\n",
      "|POLYGON ((-104.56...| 35|011|00933054|35011|  De Baca|  De Baca County| 06| H1|G4020|    |     |    |   A|6015539696|29159492|+34.3592729|-104.3686961|\n",
      "|POLYGON ((-96.910...| 31|109|00835876|31109|Lancaster|Lancaster County| 06| H1|G4020| 339|30700|    |   A|2169240202|22877180|+40.7835474|-096.6886584|\n",
      "|POLYGON ((-98.273...| 31|129|00835886|31129| Nuckolls| Nuckolls County| 06| H1|G4020|    |     |    |   A|1489645187| 1718484|+40.1764918|-098.0468422|\n",
      "+--------------------+---+---+--------+-----+---------+----------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Adapter.toDf(wkt_rdd, spark).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WKB - load to SpatialRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkb_rdd = WkbReader.readToGeometryRDD(sc, \"data/county_small_wkb.tsv\", 0, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+--------+-----+---------+----------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+\n",
      "|            geometry|_c1|_c2|     _c3|  _c4|      _c5|             _c6|_c7|_c8|  _c9|_c10| _c11|_c12|_c13|      _c14|    _c15|       _c16|        _c17|\n",
      "+--------------------+---+---+--------+-----+---------+----------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+\n",
      "|POLYGON ((-97.019...| 31|039|00835841|31039|   Cuming|   Cuming County| 06| H1|G4020|    |     |    |   A|1477895811|10447360|+41.9158651|-096.7885168|\n",
      "|POLYGON ((-123.43...| 53|069|01513275|53069|Wahkiakum|Wahkiakum County| 06| H1|G4020|    |     |    |   A| 682138871|61658258|+46.2946377|-123.4244583|\n",
      "|POLYGON ((-104.56...| 35|011|00933054|35011|  De Baca|  De Baca County| 06| H1|G4020|    |     |    |   A|6015539696|29159492|+34.3592729|-104.3686961|\n",
      "|POLYGON ((-96.910...| 31|109|00835876|31109|Lancaster|Lancaster County| 06| H1|G4020| 339|30700|    |   A|2169240202|22877180|+40.7835474|-096.6886584|\n",
      "|POLYGON ((-98.273...| 31|129|00835886|31129| Nuckolls| Nuckolls County| 06| H1|G4020|    |     |    |   A|1489645187| 1718484|+40.1764918|-098.0468422|\n",
      "+--------------------+---+---+--------+-----+---------+----------------+---+---+-----+----+-----+----+----+----------+--------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Adapter.toDf(wkb_rdd, spark).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
